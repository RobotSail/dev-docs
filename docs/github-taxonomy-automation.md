# GitHub Automation for Taxonomy

This document describes the GitHub automation used with the
[Taxonomy](https://github.com/instruct-lab/taxonomy) repository.

![GitHub Automation for Taxonomy](images/github-taxonomy-automation.excalidraw.png)

## Key Components

### InstructLab Bot

There is a [GitHub bot](https://github.com/instruct-lab/instruct-lab-bot) used
to facilitate this automation. This bot receives GitHub events and performs
actions on behalf of different components within Instruct Lab. More details on
the architectecture of the bot itself can be found in its repository.

### GitHub Actions

Not everything needs to be orchestrated by an external bot. The bot is good for
facilitating user interactions and managing long-running tasks on custom
infrastructure. However, many simpler tasks should just be GitHub actions. These
are easier to write and maintain, and they can be triggered by a variety of
events.

### Mergify (future)

[Mergify](https://docs.mergify.com) is a tool that can perform workflow
automation for a GitHub repository. It can be used to implement a variety of
automation tasks, such as automatically merging PRs when certain conditions are
met. While not yet in use, it should be kept in mind for future needs.

## Points of Interaction

### Access Controls

Team membership for triagers of the Taxonomy repository is managed using the
[taxonomy-triagers GitHub
team](https://github.com/orgs/instruct-lab/teams/taxonomy-triagers).

The bot commands can be configured to only run if a specified lab is present
on the PR. This will allow us to block the automation from running on PRs until
a triager has done an initial check and determined it is safe to proceed.

* [Bot PR adding gating label support](https://github.com/instruct-lab/instruct-lab-bot/pull/120)

Two labels will be used:

* `skill` - This label indicates that the bot can run automation intended for skills PRs.
* `knowledge` - This label indicates that the bot can run automation intended for knowledge PRs.

### Pre-Check Using the Existing Model

The trigger for this step should be a PR comment with the following format:

```text
@instruct-lab-bot precheck
```

At this point, the bot will kick off a process that will run the questions from
the `qna.yaml` against the existing Merlinite model. The intent is to allow
contributors and reviewers to see if the proposed addition is already a
capability of the model by comparing the model's answers to the provided sample
answers.

When the process is complete, the bot will post a comment with instructions on
how to access the results.

* <https://github.com/instruct-lab/instruct-lab-bot/issues/85>

### Post-Check Using the Trained Model

The trigger for this step should be a PR comment with the following format:

```text
@instruct-lab-bot postcheck
```

At this point, the bot will kick off a process that will run the questions from
the `qna.yaml` against the new Merlinite model. This will allow contributors and
triagers to see how the new model behaves for the sample questions.

The GitHub bot will manage this process, but the actual model training will be
done by the backend pipeline. The bot will hit an API endpoint that is serving
the new, candidate model. The exact API endpoint is a private endpoint hosted by
backend infrastructure.

When the process is complete, the bot will post a comment with instructions on
how to access the results.

* <https://github.com/instruct-lab/instruct-lab-bot/issues/127>

### Synthetic Data Generation Check

The trigger for this step should be a PR comment with the following format:

```text
@instruct-lab-bot generate
```

At this point, the bot will kick off a process that will generate a sample of
synthetic data generated by the Mixtral model. This is to allow contributors and
reviewers to determine if the synthetic data generated as a result of the
proposed addition is reasonable.

When the process is complete, the bot will post a comment with instructions on
how to access the results.

* Working, but still needs remote endpoint support added:
  <https://github.com/instruct-lab/instruct-lab-bot/issues/116>

### Publishing Benchmark Results

After a model build is complete, PRs included in that model should be updated to
include the before and after benchmark results.  At the end of the backend
pipeline, there is a need to post content back to a PR with the results of the
pipeline.

#### Short Term

The orchestrator is responsible for running the benchmarking process. Afterwards, a triager will run a script that publishes the results back to PRs. This script will use the triager's own GitHub credentials to post the results.

* <https://github.com/instruct-lab/orchestrator/issues/42>
* <https://github.com/instruct-lab/orchestrator/pull/72>

#### Future

Once the benchmarking process is complete, we should be able to automatically
post the results. The details here depend heavily on the design of the backend
pipeline as more of it is controlled by automation. At that point, it may make sense
to have those results posted to a queue for any other component in the overall system
that wants to know when results are available so they can be acted upon. The
GitHub bot is one such component that could get the results, and formulate them
into a comment on the PR.

### Triggering the Backend Pipeline

At some point, there is a need to trigger the backend pipeline to run its full
process. Automation should help enable this. This document needs to be updated
with additional details on this, as it likely could be triggered off of a
GitHub event, like candidate branch creation.